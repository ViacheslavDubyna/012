{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практична робота: Нейронні мережі з TensorFlow - Додаткові завдання"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання 1: Регресійна модель для прогнозу витрат ресурсів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Генерація даних для регресії (прогноз витрат ресурсів)\n",
    "X, y = make_regression(n_samples=1000, n_features=15, noise=0.1, random_state=42)\n",
    "\n",
    "# Додамо нелінійність до даних для більш реалістичного сценарію\n",
    "y = y + 0.1 * np.random.randn(1000) * np.abs(y)\n",
    "\n",
    "# Розділення даних на тренувальну та тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Нормалізація даних\n",
    "scaler_X = StandardScaler()\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "y_test_scaled = scaler_y.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# Побудова регресійної моделі з кількома прихованими шарами\n",
    "model_mse = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),  # Додаємо dropout для запобігання перенавчання\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)  # Вихідний шар без активації для регресії\n",
    "])\n",
    "\n",
    "# Компіляція моделі з функцією втрат MSE (Mean Squared Error)\n",
    "model_mse.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "model_mse.summary()\n",
    "\n",
    "# Навчання моделі\n",
    "history_mse = model_mse.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_scaled, y_test_scaled),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Оцінка моделі\n",
    "mse_loss, mse_mae = model_mse.evaluate(X_test_scaled, y_test_scaled)\n",
    "print(f\"MSE модель - Середня абсолютна помилка (MAE): {mse_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Побудова регресійної моделі з функцією втрат MAE (Mean Absolute Error)\n",
    "model_mae = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Компіляція моделі з функцією втрат MAE\n",
    "model_mae.compile(optimizer=Adam(learning_rate=0.001), loss='mae', metrics=['mse'])\n",
    "model_mae.summary()\n",
    "\n",
    "# Навчання моделі\n",
    "history_mae = model_mae.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_scaled, y_test_scaled),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Оцінка моделі\n",
    "mae_loss, mae_mse = model_mae.evaluate(X_test_scaled, y_test_scaled)\n",
    "print(f\"MAE модель - Середньоквадратична помилка (MSE): {mae_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Побудова регресійної моделі з функцією втрат Huber (комбінація MSE та MAE)\n",
    "model_huber = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Компіляція моделі з функцією втрат Huber\n",
    "model_huber.compile(\n",
    "    optimizer=Adam(learning_rate=0.001), \n",
    "    loss=tf.keras.losses.Huber(delta=1.0), \n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "model_huber.summary()\n",
    "\n",
    "# Навчання моделі\n",
    "history_huber = model_huber.fit(\n",
    "    X_train_scaled, y_train_scaled,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_scaled, y_test_scaled),\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Оцінка моделі\n",
    "huber_loss, huber_mae, huber_mse = model_huber.evaluate(X_test_scaled, y_test_scaled)\n",
    "print(f\"Huber модель - Середня абсолютна помилка (MAE): {huber_mae:.4f}\")\n",
    "print(f\"Huber модель - Середньоквадратична помилка (MSE): {huber_mse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Порівняння результатів різних функцій втрат\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Графік історії навчання для MSE\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_mse.history['loss'], label='Тренувальна вибірка')\n",
    "plt.plot(history_mse.history['val_loss'], label='Тестова вибірка')\n",
    "plt.title('MSE: Функція втрат')\n",
    "plt.xlabel('Епоха')\n",
    "plt.ylabel('Втрати')\n",
    "plt.legend()\n",
    "\n",
    "# Графік історії навчання для MAE\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history_mae.history['loss'], label='Тренувальна вибірка')\n",
    "plt.plot(history_mae.history['val_loss'], label='Тестова вибірка')\n",
    "plt.title('MAE: Функція втрат')\n",
    "plt.xlabel('Епоха')\n",
    "plt.ylabel('Втрати')\n",
    "plt.legend()\n",
    "\n",
    "# Графік історії навчання для Huber\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(history_huber.history['loss'], label='Тренувальна вибірка')\n",
    "plt.plot(history_huber.history['val_loss'], label='Тестова вибірка')\n",
    "plt.title('Huber: Функція втрат')\n",
    "plt.xlabel('Епоха')\n",
    "plt.ylabel('Втрати')\n",
    "plt.legend()\n",
    "\n",
    "# Порівняння MAE для всіх моделей\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.bar(['MSE модель', 'MAE модель', 'Huber модель'], [mse_mae, mae_loss, huber_mae])\n",
    "plt.title('Порівняння MAE для різних функцій втрат')\n",
    "plt.ylabel('MAE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Висновки\n",
    "print(\"Висновки щодо регресійних моделей:\")\n",
    "print(f\"1. MSE модель - MAE: {mse_mae:.4f}\")\n",
    "print(f\"2. MAE модель - MAE: {mae_loss:.4f}\")\n",
    "print(f\"3. Huber модель - MAE: {huber_mae:.4f}\")\n",
    "\n",
    "# Визначення найкращої моделі за MAE\n",
    "best_model = min([(\"MSE\", mse_mae), (\"MAE\", mae_loss), (\"Huber\", huber_mae)], key=lambda x: x[1])\n",
    "print(f\"\nНайкраща модель за MAE: {best_model[0]} з показником {best_model[1]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання 2: Класифікаційна модель для розпізнавання типу атаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Генерація даних для класифікації типів атак (4 класи)\n",
    "X, y = make_classification(\n",
    "    n_samples=2000, \n",
    "    n_features=20, \n",
    "    n_informative=15, \n",
    "    n_redundant=5, \n",
    "    n_classes=4, \n",
    "    weights=[0.7, 0.1, 0.1, 0.1],  # Імітуємо незбалансовані дані (більше нормальних з'єднань)\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Розділення даних на тренувальну та тестову вибірки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Нормалізація даних\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# One-hot кодування міток класів\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_train_encoded = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "y_test_encoded = encoder.transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Побудова класифікаційної моделі для розпізнавання типу атаки\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),  # Додаємо нормалізацію пакетів для стабільності навчання\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(4, activation='softmax')  # 4 класи атак\n",
    "])\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "# Додаємо ранню зупинку для запобігання перенавчанню\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Навчання моделі\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_encoded,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_scaled, y_test_encoded),\n",
    "    callbacks=[early_stopping],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Оцінка моделі\n",
    "loss, accuracy, precision, recall = model.evaluate(X_test_scaled, y_test_encoded)\n",
    "print(f\"Точність моделі: {accuracy:.4f}\")\n",
    "print(f\"Точність (Precision): {precision:.4f}\")\n",
    "print(f\"Повнота (Recall): {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отримання прогнозів моделі\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Обчислення метрик класифікації\n",
    "print(\"\nЗвіт класифікації:\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Нормальний', 'Атака DoS', 'Атака U2R', 'Атака R2L']))\n",
    "\n",
    "# Обчислення F1-score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "\n",
    "# Візуалізація матриці помилок\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Нормальний', 'Атака DoS', 'Атака U2R', 'Атака R2L'],\n",
    "           yticklabels=['Нормальний', 'Атака DoS', 'Атака U2R', 'Атака R2L'])\n",
    "plt.title('Матриця помилок')\n",
    "plt.xlabel('Прогнозований клас')\n",
    "plt.ylabel('Справжній клас')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Візуалізація історії навчання\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Тренувальна вибірка')\n",
    "plt.plot(history.history['val_accuracy'], label='Тестова вибірка')\n",
    "plt.title('Точність моделі')\n",
    "plt.xlabel('Епоха')\n",
    "plt.ylabel('Точність')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Тренувальна вибірка')\n",
    "plt.plot(history.history['val_loss'], label='Тестова вибірка')\n",
    "plt.title('Функція втрат')\n",
    "plt.xlabel('Епоха')\n",
    "plt.ylabel('Втрати')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Висновки\n",
    "print(\"\nВисновки щодо класифікаційної моделі:\")\n",
    "print(f\"1. Загальна точність: {accuracy:.4f}\")\n",
    "print(f\"2. Precision: {precision:.4f}\")\n",
    "print(f\"3. Recall: {recall:.4f}\")\n",
    "print(f\"4. F1-score: {f1:.4f}\")\n",
    "print(\"5. Модель краще розпізнає нормальні з'єднання, ніж атаки, що відображає незбалансованість даних.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання 3: Експерименти з різними функціями активації"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Генерація даних для класифікації\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Нормалізація даних\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Функція для створення моделі з заданою функцією активації\n",
    "def create_model(activation_function):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation=activation_function, input_shape=(10,)),\n",
    "        Dense(32, activation=activation_function),\n",
    "        Dense(16, activation=activation_function),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Список функцій активації для експериментів\n",
    "activation_functions = ['relu', 'tanh', 'sigmoid']\n",
    "\n",
    "# Словники для зберігання результатів\n",
    "histories = {}\n",
    "accuracies = {}\n",
    "training_times = {}\n",
    "\n",
    "# Навчання моделей з різними функціями активації\n",
    "for activation in activation_functions:\n",
    "    print(f\"\nНавчання моделі з функцією активації {activation}...\")\n",
    "    \n",
    "    # Створення моделі\n",
    "    model = create_model(activation)\n",
    "    \n",
    "    # Вимірювання часу навчання\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Навчання моделі\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=30,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test_scaled, y_test),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Збереження часу навчання\n",
    "    training_times[activation] = time.time() - start_time\n",
    "    \n",
    "    # Оцінка моделі\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "    print(f\"Точність моделі з {activation}: {accuracy:.4f}\")\n",
    "    \n",
    "    # Збереження результатів\n",
    "    histories[activation] = history.history\n",
    "    accuracies[activation] = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Візуалізація результатів\n",